{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name : Aaditya Kulkarni\n",
    "ID no : 2021A7PS0426P\n",
    "University Email ID : f20210426@pilani.bits-pilani.ac.in\n",
    "Personal Email ID : adityakulk0301@gmail.com\n",
    "BITS Pilani - Pilani Campus\n",
    "B.E. Computer Science\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file needs some imports to function properly - mentioned in the requirements.txt file\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.graph_objs as go\n",
    "from dash.dependencies import Input, Output\n",
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We create a dash app that displays a live updating graph of random data. \n",
    "The user can select between three different anomaly detection methods: Z-Score, Exponential Moving Average, and Local Outlier Factor.\n",
    "\"\"\"\n",
    "\n",
    "# We first initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# We create the layout of the app\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='live-graph'),\n",
    "    dcc.Interval(id='graph-update', interval=1000, n_intervals=0),  # Updates the graph every second\n",
    "    html.Div(\"Anomaly Detection Method:\"),\n",
    "    dcc.RadioItems(\n",
    "        id='anomaly-method',\n",
    "        options=[\n",
    "            {'label': 'Z-Score', 'value': 'zscore'},\n",
    "            {'label': 'Exponential Moving Average', 'value': 'ema'},\n",
    "            {'label': 'Local Outlier Factor', 'value': 'lof'},\n",
    "        ],\n",
    "        value='zscore',  # Value default to Z-score\n",
    "        inline=True\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We initialize the data that will be used to generate the graph, along with the anomalies that will be detected.\n",
    "\"\"\"\n",
    "x_data = []  # Time points on X-axis\n",
    "y_data = []  # Transaction values on Y-axis\n",
    "anomalies = []  # Store anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We define the function that will generate the financial data.\n",
    "The function generates a random transaction value at time t, with a seasonal effect and random noise.\n",
    "Occasionally, an anomaly is introduced, which is a random spike or drop in the transaction value.\n",
    "We also add data validation to ensure that the generated values are valid.\n",
    "We have also added a try-except block to catch any errors that may occur during data generation.\n",
    "The function returns the transaction value and a boolean indicating whether it is an anomaly.\n",
    "\n",
    "For the data stream, we are just appending the newly generated data at time t to the existing data\n",
    "- this is because we are simulating a live data stream where new data points are continuously added.\n",
    "This type of data streaming makes more sense when we are dealing with real-time data, such as financial transactions.\n",
    "\n",
    "NOTE:\n",
    "There is another type of real-time data streaming where every point from 0 to t gets generated every second but it is not a good idea for financial transactions data generation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def generate_financial_data(t):\n",
    "    try:\n",
    "        base_value = np.random.normal(100, 10)  # Base transaction value with normal distribution with mean 100 and std 10. This simulates the regular transaction amounts in the data stream.\n",
    "        seasonal_effect = 20 * np.sin(t / 60)  # Seasonal effect with a period of 60 time units. This simulates predictable but fluctuations in transaction amounts.\n",
    "        noise = np.random.normal(0, 5)  # Random gaussian noise with mean 0 and std 5. This simulates the unpredictable random fluctuations in transaction amounts.\n",
    "        anomaly = 0\n",
    "\n",
    "        # Occasionally introduce an anomaly\n",
    "        if np.random.rand() < 0.1:  # 10% chance of an anomaly\n",
    "            anomaly = np.random.uniform(-100, 200)  # Random spike or drop\n",
    "\n",
    "        # Transaction value is the sum of base value, seasonal effect, noise, and anomaly\n",
    "        transaction_value = base_value + seasonal_effect + noise + anomaly\n",
    "        \n",
    "        # Data validation\n",
    "        if np.isnan(transaction_value) or np.isinf(transaction_value):  # Check for NaN or infinity\n",
    "            raise ValueError(f\"Invalid transaction value generated at time {t}: {transaction_value}\")\n",
    "\n",
    "        return transaction_value, anomaly != 0  # Return if it's an anomaly\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating data at time {t}: {e}\")\n",
    "        return None, False  # In case of error, return None and no anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detecting anomalies using Z-Score method\n",
    "The Z-score method detects anomalies by measuring how far each data point deviates from the mean of the data in terms of standard deviations.\n",
    "Z-score is calculated as the difference between the data point and the mean divided by the standard deviation.\n",
    "If the absolute Z-score of a data point is greater than a threshold (e.g., 3), it is considered an anomaly.\n",
    "We have also added a try-except block to catch any errors that may occur during anomaly detection.\n",
    "\n",
    "Reason for choosing Z-Score:\n",
    "Z-score is simple and effective for identifying large deviations from the mean, which can indicate anomalies in financial data.\n",
    "It is a statistical approach that is well-suited to data with a relatively stable mean and standard deviation.\n",
    "\"\"\"\n",
    "def detect_anomalies_zscore(y_data):\n",
    "    try:\n",
    "        if len(y_data) < 2:  # We need at least two points to compute mean and std\n",
    "            return []\n",
    "\n",
    "        mean = np.mean(y_data)\n",
    "        std_dev = np.std(y_data)\n",
    "\n",
    "        if std_dev == 0:\n",
    "            return []  # To avoid division by zero\n",
    "\n",
    "        z_scores = [(y - mean) / std_dev for y in y_data]\n",
    "        anomaly_indices = [i for i, z in enumerate(z_scores) if abs(z) > 3]\n",
    "\n",
    "        return anomaly_indices\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting anomalies with Z-score: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detecting anomalies using Exponential Moving Average (EMA) method\n",
    "The EMA method detects anomalies by comparing the original data with the exponentially smoothed data.\n",
    "EMA is calculated as a weighted average of the current data point and the previous EMA value, more specifically:\n",
    "EMA(t) = alpha * data(t) + (1 - alpha) * EMA(t-1) where alpha is the smoothing factor (e.g., 0.1).\n",
    "The residuals are calculated as the absolute difference between the original data and the EMA.\n",
    "If the residual of a data point is greater than a threshold (e.g., 2 times the standard deviation of residuals), it is considered an anomaly.\n",
    "We have also added a try-except block to catch any errors that may occur during anomaly detection.\n",
    "\n",
    "Reason for choosing EMA:\n",
    "EMA adapts well to trends and shifts in data, making it ideal for time series with short-term fluctuations.\n",
    "It helps capture gradual shifts in financial transaction patterns and highlights deviations from expected trends.\n",
    "\"\"\"\n",
    "def detect_anomalies_ema(y_data, alpha=0.1):\n",
    "    try:\n",
    "        if len(y_data) < 2:\n",
    "            return []\n",
    "\n",
    "        ema = [y_data[0]]  # Start EMA with the first value of the series\n",
    "        for i in range(1, len(y_data)):\n",
    "            ema.append(alpha * y_data[i] + (1 - alpha) * ema[-1])\n",
    "\n",
    "        residuals = np.abs(np.array(y_data) - np.array(ema))\n",
    "        anomaly_indices = [i for i, res in enumerate(residuals) if res > 2 * np.std(residuals)]\n",
    "\n",
    "        return anomaly_indices\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting anomalies with EMA: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detecting anomalies using Local Outlier Factor (LOF) method\n",
    "The LOF method detects anomalies by comparing the local density of a data point with the local densities of its neighbors.\n",
    "A data point is considered an anomaly if its local density is significantly lower than the local densities of its neighbors.\n",
    "We have used nearest neighbors parameter n_neighbors=5 for LOF.\n",
    "We have also added a try-except block to catch any errors that may occur during anomaly detection.\n",
    "\"\"\"\n",
    "def detect_anomalies_lof(y_data):\n",
    "    try:\n",
    "        if len(y_data) < 5:  # LOF needs atleast 5 points (based on n_neighbors=5)\n",
    "            return []\n",
    "\n",
    "        lof = LocalOutlierFactor(n_neighbors=5)\n",
    "        y_data_reshaped = np.array(y_data).reshape(-1, 1)\n",
    "        y_pred = lof.fit_predict(y_data_reshaped)\n",
    "\n",
    "        anomaly_indices = np.where(y_pred == -1)[0].tolist() # Anomalies are labeled as -1 by LOF\n",
    "\n",
    "        return anomaly_indices\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting anomalies with LOF: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This callback updates the real-time graph each second (n_intervals) and applies the selected anomaly detection method.\n",
    "It appends the new transaction value to the data stream, detects anomalies using the chosen method (Z-score, EMA, or LOF),and stores any detected anomalies in a list. \n",
    "The graph is updated with the new transaction data and anomalies, if any, marking anomalies as red dots. \n",
    "The graph dynamically adjusts its x-axis (time) and y-axis (transaction value) to show the last 60 seconds.\n",
    "Error handling ensures smooth graph updates even in case of data issues.\n",
    "\"\"\"\n",
    "@app.callback(\n",
    "    Output('live-graph', 'figure'),\n",
    "    [Input('graph-update', 'n_intervals'), Input('anomaly-method', 'value')]\n",
    ")\n",
    "def update_graph(n, method):\n",
    "    global x_data, y_data, anomalies\n",
    "\n",
    "    try:\n",
    "        # We just append the new point in the end of list(t-th second)\n",
    "        x_data.append(n)\n",
    "        transaction_value, is_anomaly = generate_financial_data(n)\n",
    "\n",
    "        # Only appending valid data\n",
    "        if transaction_value is not None:\n",
    "            y_data.append(transaction_value)\n",
    "\n",
    "            # Detect anomalies based on the selected method\n",
    "            if method == 'zscore':\n",
    "                anomaly_indices = detect_anomalies_zscore(y_data)\n",
    "            elif method == 'ema':\n",
    "                anomaly_indices = detect_anomalies_ema(y_data)\n",
    "            elif method == 'lof':\n",
    "                anomaly_indices = detect_anomalies_lof(y_data)\n",
    "\n",
    "            # We save anomalies in a list\n",
    "            if is_anomaly:\n",
    "                anomalies.append((n, transaction_value))\n",
    "\n",
    "            # Create the plotly figure for the graph\n",
    "            fig = go.Figure()\n",
    "\n",
    "            # Adding the main data line\n",
    "            fig.add_trace(go.Scatter(x=x_data, y=y_data, mode='lines', name='Transactions'))\n",
    "\n",
    "            # Marking anomalies (they won't disappear once detected)\n",
    "            for idx in anomaly_indices:\n",
    "                anomalies.append((x_data[idx], y_data[idx]))\n",
    "\n",
    "            if anomalies:\n",
    "                anomaly_times, anomaly_values = zip(*anomalies) # Unzip the anomalies into times and values\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=anomaly_times,\n",
    "                    y=anomaly_values,\n",
    "                    mode='markers',\n",
    "                    marker=dict(color='red', size=10),\n",
    "                    name='Anomalies'\n",
    "                ))\n",
    "\n",
    "            # We need to keep updating the layout of the graph, so it shows the last 60 seconds\n",
    "            fig.update_layout(\n",
    "                title='Real-Time Financial Transactions with Anomalies',\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Transaction Value',\n",
    "                xaxis=dict(range=[n - 60, n]),  \n",
    "                yaxis=dict(range=[min(y_data[-60:]) - 10, max(y_data[-60:]) + 10])  # Adjust y-axis dynamically\n",
    "            )\n",
    "\n",
    "            return fig\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating graph at interval {n}: {e}\")\n",
    "        return go.Figure()  # Return an empty figure on error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8068/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18772767d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Running the dash app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8068)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
